<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-colors-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="built-on" content="2024-02-04T00:19:37.685593"><title>大規模言語モデルについて | LLM：ゼロからエキスパートへ</title><script type="application/json" id="virtual-toc-data">[{"id":"model","level":0,"title":"プリトレーニング:基本Model","anchor":"#model"},{"id":"5873e0ac_1412","level":0,"title":"ファインチューニング:アシスタントのトレーニング","anchor":"#5873e0ac_1412"},{"id":"5873e0ac_1437","level":0,"title":"人間のフィードバックからの強化学習","anchor":"#5873e0ac_1437"},{"id":"5873e0ac_1476","level":0,"title":"プロンプトエンジニアリング","anchor":"#5873e0ac_1476"},{"id":"5873e0ac_1526","level":0,"title":"まとめ","anchor":"#5873e0ac_1526"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.6.6-b205/app.css" rel="stylesheet"><link rel="icon" type="image/png" sizes="16x16" href="images/cropped_logo.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="大規模言語モデルについて | LLM：ゼロからエキスパートへ"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="LLM：ゼロからエキスパートへ Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="/japanese/how-llm-works-jp.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="大規模言語モデルについて | LLM：ゼロからエキスパートへ"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "/japanese/how-llm-works-jp.html#webpage",
    "url": "/japanese/how-llm-works-jp.html",
    "name": "大規模言語モデルについて | LLM：ゼロからエキスパートへ",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "/japanese/#website",
    "url": "/japanese/",
    "name": "LLM：ゼロからエキスパートへ Help"
}</script><!-- End Schema.org --></head><body data-id="How-LLM-Works-JP" data-main-title="大規模言語モデルについて" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>LLM：ゼロからエキスパートへ  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="How-LLM-Works-JP" id="How-LLM-Works-JP.md">大規模言語モデルについて</h1><p id="5873e0ac_1379">1)ドキュメント_コンプリーター_Modelは、以下のように機能します。</p><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="-8 -8 431.703125 96.3125" height="96.3125" xmlns="http://www.w3.org/2000/svg" width="431.703125" id="mermaid"><g><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="10" viewBox="0 0 12 20" class="marker flowchart" id="flowchart-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="0" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart" id="flowchart-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart" id="flowchart-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"><path marker-end="url(#flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-head LE-torso" id="L-head-torso-0" d="M66.515625,40.15625L73.42057291666667,40.15625C80.32552083333333,40.15625,94.13541666666667,40.15625,107.9453125,40.15625C121.75520833333333,40.15625,135.56510416666666,40.15625,142.47005208333334,40.15625L149.375,40.15625"></path><path marker-end="url(#flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-torso LE-tail" id="L-torso-tail-0" d="M252.53125,40.15625L259.4361979166667,40.15625C266.3411458333333,40.15625,280.1510416666667,40.15625,293.9609375,40.15625C307.7708333333333,40.15625,321.5807291666667,40.15625,328.4856770833333,40.15625L335.390625,40.15625"></path></g><g class="edgeLabels"><g transform="translate(107.9453125, 40.15625)" class="edgeLabel"><g transform="translate(-16.4296875, -9.25)" class="label"><foreignObject height="18.5" width="32.859375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">send</span></div></foreignObject></g></g><g transform="translate(293.9609375, 40.15625)" class="edgeLabel"><g transform="translate(-16.4296875, -9.25)" class="label"><foreignObject height="18.5" width="32.859375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">send</span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(33.2578125, 40.15625)" id="flowchart-head-258" class="node default default flowchart-label"><circle height="33.5" width="66.515625" r="33.2578125" ry="0" rx="0" style=""></circle><g transform="translate(-25.7578125, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="51.515625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Prompt</span></div></foreignObject></g></g><g transform="translate(200.953125, 40.15625)" id="flowchart-torso-259" class="node default default flowchart-label"><rect height="33.5" width="103.15625" y="-16.75" x="-51.578125" ry="16.75" rx="16.75" style=""></rect><g transform="translate(-39.890625, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="79.78125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Base Model</span></div></foreignObject></g></g><g transform="translate(375.546875, 40.15625)" id="flowchart-tail-260" class="node default default flowchart-label"><circle height="33.5" width="80.3125" r="40.15625" ry="0" rx="0" style=""></circle><g transform="translate(-32.65625, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="65.3125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Response</span></div></foreignObject></g></g></g></g></g></svg><p id="5873e0ac_1381"><span class="emphasis" id="5873e0ac_1382">ユーザープロンプト:</span></p><div class="code-block" data-lang="plaintext">
A banana is
</div><p id="5873e0ac_1384"><span class="emphasis" id="5873e0ac_1385">modelの回答:</span></p><div class="code-block" data-lang="plaintext">
an elongated, edible fruit
</div><p id="5873e0ac_1387">2)ドキュメント_ジェネレーター_Modelは、以下のように機能します。</p><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="-8 -8 534.03125 96.3125" height="96.3125" xmlns="http://www.w3.org/2000/svg" width="534.03125" id="mermaid"><g><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="10" viewBox="0 0 12 20" class="marker flowchart" id="flowchart-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="0" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart" id="flowchart-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart" id="flowchart-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart" id="flowchart-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"><path marker-end="url(#flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-head LE-torso" id="L-head-torso-0" d="M66.515625,40.15625L73.42057291666667,40.15625C80.32552083333333,40.15625,94.13541666666667,40.15625,107.9453125,40.15625C121.75520833333333,40.15625,135.56510416666666,40.15625,142.47005208333334,40.15625L149.375,40.15625"></path><path marker-end="url(#flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-torso LE-tail" id="L-torso-tail-0" d="M354.859375,40.15625L361.7643229166667,40.15625C368.6692708333333,40.15625,382.4791666666667,40.15625,396.2890625,40.15625C410.0989583333333,40.15625,423.9088541666667,40.15625,430.8138020833333,40.15625L437.71875,40.15625"></path></g><g class="edgeLabels"><g transform="translate(107.9453125, 40.15625)" class="edgeLabel"><g transform="translate(-16.4296875, -9.25)" class="label"><foreignObject height="18.5" width="32.859375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">send</span></div></foreignObject></g></g><g transform="translate(396.2890625, 40.15625)" class="edgeLabel"><g transform="translate(-16.4296875, -9.25)" class="label"><foreignObject height="18.5" width="32.859375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">send</span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(33.2578125, 40.15625)" id="flowchart-head-267" class="node default default flowchart-label"><circle height="33.5" width="66.515625" r="33.2578125" ry="0" rx="0" style=""></circle><g transform="translate(-25.7578125, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="51.515625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Prompt</span></div></foreignObject></g></g><g transform="translate(252.1171875, 40.15625)" id="flowchart-torso-268" class="node default default flowchart-label"><rect height="33.5" width="205.484375" y="-16.75" x="-102.7421875" ry="16.75" rx="16.75" style=""></rect><g transform="translate(-91.0546875, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="182.109375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Fine-tuned &amp; RLHF Model</span></div></foreignObject></g></g><g transform="translate(477.875, 40.15625)" id="flowchart-tail-269" class="node default default flowchart-label"><circle height="33.5" width="80.3125" r="40.15625" ry="0" rx="0" style=""></circle><g transform="translate(-32.65625, -9.25)" style="" class="label"><rect></rect><foreignObject height="18.5" width="65.3125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Response</span></div></foreignObject></g></g></g></g></g></svg><p id="5873e0ac_1389"><span class="emphasis" id="5873e0ac_1390">ユーザープロンプト:</span></p><div class="code-block" data-lang="plaintext">
I want to buy a new car
</div><p id="5873e0ac_1392"><span class="emphasis" id="5873e0ac_1393">modelの回答:</span></p><div class="code-block" data-lang="plaintext">
What kind of car do you want to buy?
</div><p id="5873e0ac_1395">上記の二つのModelの違いについては、</p><p id="5873e0ac_1396">一つ目のModelは単なるドキュメントコンプリーターで、プロンプトに続く最も可能性の高い次の文字を完成させます。 これはインターネットのデータの一部に基づいて訓練されたModelで、基本Modelと呼ばれます。</p><p id="5873e0ac_1397">二つ目のModelは、ドキュメントジェネレーターで、プロンプトの質問に基づいて_人間のような_回答を生成します。 これはChatGPTのModelです。</p><p id="5873e0ac_1398">ChatGP Modelは、プロンプトの質問に基づいて応答を生成できる推論Modelです。 基本Modelとほぼ99%同じですが、ファインチューニングと人間のフィードバックからの強化学習の二つの追加トレーニングステップがあります。</p><section class="chapter"><h2 id="model" data-toc="model">プリトレーニング:基本Model</h2><p id="5873e0ac_1399">これはAI革命の真核であり、まさに魔法が宿っていると言えます。</p><p id="5873e0ac_1400">Modelのトレーニングは、大量のデータをフィードして、それから学習させるピロセスです。</p><p id="5873e0ac_1401">GPT-３の論文<a href="https://arxiv.org/abs/2005.14165" id="5873e0ac_1402" data-external="true" rel="noopener noreferrer">GPT-3 paper</a>の記載されているように、基本Modelはインターネットのデータの大きな塊に基づいてトレーニングされます。</p><p id="5873e0ac_1403">これは我々にとって容易な作業ではありませんが、データの取得だけではなく、GPUやTPUのような多大な計算能力を必要とするためです。 私たちでも、自分のコンピュータ上で小さなGPT Modelをトレーニングする方法を学ぶことができますが、その方法は次のブログで説明します。</p><p id="5873e0ac_1404">LLMトレーニングの革新性は、Transformerアーキテクチャの導入にあります。 これにより、Modelは膨大なデータから学習しつつ、入力の異なる部分の重要な_文脈関係_を保持することが可能になります。</p><p id="5873e0ac_1405">これらの接続を維持することで、Modelは提供された文脈に基づいて新たな洞察を効果的に推測することができます。</p><p id="5873e0ac_1406">それが個々の単語であれ、段落であれ、文書であれ、それ以上のものであれ、この能力により、 LLMトレーニングは自然言語処理と生成のタスクに新たな機会を開き、マシンが人間のコミュニケーションをよりよく理解し、応答することを可能にしました。</p><p id="5873e0ac_1407">基本Modelのトレーニングに使用されるトランスフォーマーアーキテクチャは下記の通りです。</p><figure id="5873e0ac_1408"><img alt="Transformer paper architecture" src="images/transformer-paper-architecture.png" title="Transformer paper architecture" width="400" height="521"></figure><p id="5873e0ac_1409">これは、&quot;トークン化&quot;、&quot;エンベディング&quot;、&quot;ポジションエンコーディング&quot;、&quot;フィードフォワード&quot;、 &quot;レイヤーノーマライゼーション&quot;、&quot;マスキング&quot;、&quot;ソフトマックス&quot;、そして最も重要な&quot;マルチヘッドアテンション&quot;など、 古典的および新しい技術を用いたニューラルネットワークベースのModelトレーニングを示しています。」</p><p id="5873e0ac_1410">この部分は、私が最も興味を持っているところです。アーキテクチャの背後にある考え方とトレーニングがどのように正確に行われたかを明確に理解したいと思っています。</p><p id="5873e0ac_1411">そこで次のブログから、基本モデルのトレーニングに使用される論文、コード、数学について掘り下げていきます。</p></section><section class="chapter"><h2 id="5873e0ac_1412" data-toc="5873e0ac_1412">ファインチューニング:アシスタントのトレーニング</h2><p id="5873e0ac_1413">ファインチューニングはとても賢い実装方法です。 このアイデアはOpenAIによって初めて実施されたと思います。 このアイデアは非常にシンプルですが、知的に機能します。 人間のラベラーを雇って多くのQ&amp;Aの会話ペア（10万の質問と回答）を作成させます。</p><p id="5873e0ac_1414">次に、その質問と回答のペアを基本Modelにフィードして、そこから学習させます。</p><p id="5873e0ac_1415">このプロセスは_ファインチューニング_と呼ばれます。10万のサンプル会話がModelにトレーニングされた後に何か起こるか知ってますか？ Modelは人間のように質問に答えることができるようになります。</p><p id="5873e0ac_1416">これらのサンプルのラベル付けされた会話を見てみましょう</p><dl id="5873e0ac_1417" data-style="title-top"><dt id="5873e0ac_1418" data-expandable="false">Q&amp;A</dt><dd><p id="5873e0ac_1420">Q: あなたの名前は？</p><p id="5873e0ac_1421">A: 私の名前はジョンです。</p></dd><dt id="5873e0ac_1422" data-expandable="false">Q&amp;A</dt><dd><p id="5873e0ac_1424">Q: 中国の首都は？</p><p id="5873e0ac_1425">A: 中国の首都は北京です。</p></dd><dt id="5873e0ac_1426" data-expandable="false">Q&amp;A</dt><dd><p id="5873e0ac_1428">Q: 映画タイタニックのあらすじを要約してください。</p><p id="5873e0ac_1429">A: 映画タイタニックは、海で沈む船についての話です。</p></dd></dl><p id="5873e0ac_1430">これらのサンプルのQ&amp;Aは私たちが互いに話す方法を模倣しています。</p><p id="5873e0ac_1431">Modelにこれらの応答スタイルを教えることで、関連する文脈的な応答の確率が非常に高くなり、ユーザーのプロンプトに対してより良い応答となります。 様々な会話スタイルでModelをトレーニングすることにより、プロンプトに対して関連性が高く文脈に適した応答を生成する確率が高めます。</p><p id="5873e0ac_1432">これが、言語Modelが非常に知的で人間のように見える理由です。現実世界の会話のリズムやパターンを学習することで、 ユーザーとの行き来の対話を説得力を持ってシミュレートすることができます。</p><p id="5873e0ac_1433">この段階で、私たちは_アシスタントModel_と得たと言えます。 以下は、基本ModelのプリトレーニングからアシスタントModelのファインチューニングまでのいくつかのハイライトを示す図です。</p><figure id="5873e0ac_1434"><img alt="Concept base fintune" src="images/concept-base-fintune.png" title="Concept base fintune" width="600" height="304"></figure><p id="5873e0ac_1435">(from <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" id="5873e0ac_1436" data-external="true" rel="noopener noreferrer">Andrej Karpathy's build a GPT model from scratch)</a>)</p></section><section class="chapter"><h2 id="5873e0ac_1437" data-toc="5873e0ac_1437">人間のフィードバックからの強化学習</h2><p id="5873e0ac_1438">2022年1月にOpenAIは<a href="https://openai.com/research/instruction-following" id="5873e0ac_1439" data-external="true" rel="noopener noreferrer">Aligning language models to follow instructions</a> .に関する研究を公開しました。 そのブログ投稿では、Modelが人間のフィードバックを用いて、さらにファインチューニングされた方法について説明しています。</p><p id="5873e0ac_1440">これは少し複雑ですが、アイデアはModelに人間のフィードバックから学ばせることです。 約10万件のラベル付けされたQ&amp;Aペアを提供する代わりに、ユーザーのプロンプトとModelの応答を収集し, その後、人間によるランキングを行います。</p><p id="5873e0ac_1441">ランク付けされた会話を最も望ましいQ&amp;Aサンプルとして持ち、 それらを再びModelにフィードして、それから学び、全体的なパフォーマンスを改善させます。</p><p id="5873e0ac_1442">このプロセスはOpenAIによって <a href="https://openai.com/research/instruction-following" id="5873e0ac_1443" data-external="true" rel="noopener noreferrer">blog</a> :で紹介されています。</p><aside class="prompt" data-type="tip" data-title="" id="5873e0ac_1444"><p id="5873e0ac_1445">Modelをより安全、より役たつものにし、より整合性を持たせるために、人間のフィードバックから強化学習（RLHF）という既存の技術を使用しています。 APIの顧客から提供されたプロンプトに対して、私たちのラベラーは望ましいModelの振る舞いのデモンストレーションを提供し、 私たちのModelからのいくつの出力をランク付けします。それから、このデータを使用してGPT-3をファインチューニングします。</p></aside><p id="5873e0ac_1446">以下は基本Modelとファインチューニング/RLHFされた応答の比較です</p><div class="table-wrapper"><table class="wide" id="5873e0ac_1447"><thead><tr class="ijRowHead" id="5873e0ac_1448"><th id="5873e0ac_1449"><p>prompt:</p></th><th id="5873e0ac_1450"><p><span class="emphasis" id="5873e0ac_1451"><span class="control" id="5873e0ac_1452">Explain the moon landing to a 6 year old in a few sentences.</span></span></p></th></tr></thead><tbody><tr id="5873e0ac_1453"><td id="5873e0ac_1454"><p><code class="code" id="5873e0ac_1455">Base</code></p></td><td id="5873e0ac_1456"><p><span class="emphasis" id="5873e0ac_1457">Explain the theory of gravity to a 6 year old.</span></p></td></tr><tr id="5873e0ac_1458"><td id="5873e0ac_1459"></td><td id="5873e0ac_1460"><p><span class="emphasis" id="5873e0ac_1461">Explain the theory of relativity to a 6 year old in a few sentences.</span></p></td></tr><tr id="5873e0ac_1462"><td id="5873e0ac_1463"></td><td id="5873e0ac_1464"><p><span class="emphasis" id="5873e0ac_1465">Explain the big bang theory to a 6 year old.</span></p></td></tr><tr id="5873e0ac_1466"><td id="5873e0ac_1467"></td><td id="5873e0ac_1468"><p><span class="emphasis" id="5873e0ac_1469">Explain evolution to a 6 year old.</span></p></td></tr><tr id="5873e0ac_1470"><td id="5873e0ac_1471"><p><code class="code" id="5873e0ac_1472">Fine-tuned/RLHF</code></p></td><td id="5873e0ac_1473"><p><span class="emphasis" id="5873e0ac_1474">People went to the moon, and they took pictures of what they saw, and sent them back to the earth so we could all see them.</span></p></td></tr></tbody></table></div><p id="5873e0ac_1475">ファインチューニングとRLHFがなければ、Modelは単なるドキュメントコンプリーターに過ぎないことがわかります。</p></section><section class="chapter"><h2 id="5873e0ac_1476" data-toc="5873e0ac_1476">プロンプトエンジニアリング</h2><p id="5873e0ac_1477">ファインチューニングとRLHFを施しても、Modelは望ましい応答を得るための助けがまだ必要です。</p><p id="5873e0ac_1478">ここでプロンプトエンジニアリングの出番です。</p><p id="5873e0ac_1479">簡単に言うと、プロンプトを慎重に設計することで、Modelがより望ましい応答を引き出せます(時にはファインチューニング無しで）。</p><p id="5873e0ac_1480">もし数学やコーディングに深く入り込むつもりがなければ、プロンプトエンジニアリングにもっと注意を払うことをお勧めします。</p><p id="5873e0ac_1481">なぜなら、より良いプロンプトを作成するだけで、LLM Modelから最大の効果を引き出すことができるからです。</p><p id="5873e0ac_1482">では、例を見てみましょう。</p><p id="5873e0ac_1483"><span class="emphasis" id="5873e0ac_1484"><span class="control" id="5873e0ac_1485">プロンプト:</span></span></p><div class="code-block" data-lang="plaintext">
The sky is
</div><p id="5873e0ac_1487"><span class="emphasis" id="5873e0ac_1488">出力:</span></p><div class="code-block" data-lang="plaintext">
blue.
</div><p id="5873e0ac_1490"><span class="control" id="5873e0ac_1491">少し改善してみましょう</span></p><p id="5873e0ac_1492"><span class="emphasis" id="5873e0ac_1493">プロンプト:</span></p><div class="code-block" data-lang="plaintext">
Complete the sentence: 
The sky is
</div><p id="5873e0ac_1495"><span class="emphasis" id="5873e0ac_1496">出力:</span></p><div class="code-block" data-lang="plaintext">
blue during the day and dark at night.
</div><p id="5873e0ac_1498">promptにいくつかの指示を含めることで、Modelは何をするべきか、何を応答すべきかを知ることができます。</p><p id="5873e0ac_1499"><span class="control" id="5873e0ac_1500">もう一つ面白い例をみてみましょう:</span></p><p id="5873e0ac_1501"><span class="emphasis" id="5873e0ac_1502">prompt:</span></p><div class="code-block" data-lang="plaintext">
When I was 6 my sister was half my age. Now
I’m 70 how old is my sister?
</div><p id="5873e0ac_1504"><span class="emphasis" id="5873e0ac_1505">output:</span></p><div class="code-block" data-lang="plaintext">
35
</div><p id="5873e0ac_1507"><span class="control" id="5873e0ac_1508">答えは間違っています。</span> 正解は67歳です。Modelは質問を理解しているようですが、数学的な計算を参照してしまっているのではなく、 論理的な推論を行うべきです。</p><p id="5873e0ac_1509">ファインチューニングとRLHFなしで、正確な答えを得るためには、プロンプトにさらに例示的な指示を追加するだけで済みます。</p><p id="5873e0ac_1510"><span class="emphasis" id="5873e0ac_1511">prompt:</span></p><div class="code-block" data-lang="plaintext">
Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,
there will be 21 trees. How many trees did the grove workers plant today?
A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.
So, they must have planted 21 - 15 = 6 trees. The answer is 6.
Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.
Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74
chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.
Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops
did Jason give to Denny?
A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of
lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.
Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does
he have now?
A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so
in total he has 7 + 2 = 9 toys. The answer is 9.
Q: There were nine computers in the server room. Five more computers were installed each day, from
monday to thursday. How many computers are now in the server room?
A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =
20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.
The answer is 29.
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many
golf balls did he have at the end of wednesday?
A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On
Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.
Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
A: She bought 5 bagels for $3 each. This means she spent $15. She has $8 left.
Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?
A:
</div><p id="5873e0ac_1513"><span class="emphasis" id="5873e0ac_1514">output:</span></p><div class="code-block" data-lang="plaintext">
When I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70 - 3 = 67. The answer is 67.
</div><p id="5873e0ac_1516"><span class="emphasis" id="5873e0ac_1517">output 2:</span></p><div class="code-block" data-lang="plaintext">
When the narrator was 6, his sister was half his age, which is 3. Now that the narrator is 70, his sister would be 70 - 3 = 67 years old. The answer is 67.
</div><p id="5873e0ac_1519"><span class="control" id="5873e0ac_1520">両方の答えが正しいです！</span> 単にいくつかの例として論理的な説明をプロンプトに追加し、同じ質問を再度します。 Modelは今、質問を理解し、正しく答えることができます。</p><p id="5873e0ac_1521">上記の例は<a href="https://www.promptingguide.ai/techniques/consistency#:~:text=Wang%20et%20al,a%20new%20tab" id="5873e0ac_1522" data-external="true" rel="noopener noreferrer">Wang et al. (2022)</a>) によって紹介され、最終答えを算出するのにいくつかのステップが必要であるとされています。</p><p id="5873e0ac_1523">強力なプロンプトは、数学の問題を解決したり、テキストを生成したりするような複雑なタスクをModelに実行させるために使うことができます。 そのため、&quot;プロンプトエンジニアリングも&quot;もLLMエコシステムの非常に重要な役割を果たしています。</p><p id="5873e0ac_1524">プロンプトエンジニアリングについてさらに詳しくは、こちらの優れた<a href="https://www.promptingguide.ai/introduction/basics" id="5873e0ac_1525" data-external="true" rel="noopener noreferrer">prompting guide</a>チュートリアルをご覧ください。</p></section><section class="chapter"><h2 id="5873e0ac_1526" data-toc="5873e0ac_1526">まとめ</h2><p id="5873e0ac_1527">ここまで読んでくださり、特にLLMの世界に新しい方にとっては、全ての情報を消化するのに時間がかかったと思います。 本当にAIの専門家になる準備ができていると思います！</p><p id="5873e0ac_1528">今のところ、基本的な概念や背景情報について十分にカバーできたと思います。</p><p id="5873e0ac_1529">私たち自身の大規模言語Modelを構築する準備を始める時が来ました。 理論はここまでにして、 <span class="control" id="5873e0ac_1530">トランスフォーマーアーキテクチャ</span>の重要な部分に進むにあたり、実践的に取り組んでいきましょう。</p></section><div class="last-modified">Last modified: 03 February 2024</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="what-is-llm-jp.html" class="navigation-links__prev">LLMとは</a><a href="transformer-architecture-jp.html" class="navigation-links__next">トランスフォーマーアーキテクチャ</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.6.6-b205/app.js"></script></body></html>